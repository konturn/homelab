#- name: install python-setuptools
#  package:
#    name: python-setuptools
#    state: present
#  delegate_to: localhost
#
- name: Set timezone
  community.general.timezone:
    name: America/New_York

- name: Install dependencies
  apt:
    name:
      - apt-transport-https
      - ca-certificates
      - curl
      - gnupg-agent
      - software-properties-common
      - python3-pip
      - git
    state: present
    update_cache: yes

- name: Install git
  apt:
    name: git
    state: present
    update_cache: yes

- name: Create keyrings directory
  ansible.builtin.file:
    path: /etc/apt/keyrings
    state: directory
    mode: '0755'
  check_mode: no

- name: Download Docker GPG key
  ansible.builtin.get_url:
    url: "https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg"
    dest: /etc/apt/keyrings/docker.asc
    mode: '0644'
  check_mode: no

- name: Remove incorrect bookworm Docker repo from Bullseye hosts
  apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian bookworm stable"
    state: absent
  when: ansible_distribution_release == 'bullseye'

- name: Add docker repository to apt
  apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
    state: present

- name: Install docker
  apt:
    name:
      - docker-ce
      - docker-ce-cli
      - containerd.io
      - docker-compose-plugin
    state: latest
    update_cache: yes

- name: Remove legacy NVIDIA Docker GPG key
  ansible.builtin.file:
    path: /etc/apt/keyrings/nvidia-docker.asc
    state: absent
  when: nvidia_container_runtime

- name: Remove legacy NVIDIA Docker repository
  apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/nvidia-docker.asc] https://nvidia.github.io/nvidia-docker/{{ item }} /"
    state: absent
  loop:
    - "ubuntu{{ ansible_distribution_version }}/amd64"
    - "ubuntu18.04/amd64"
  when: nvidia_container_runtime
  ignore_errors: yes

- name: Download NVIDIA Container Toolkit GPG key
  ansible.builtin.get_url:
    url: https://nvidia.github.io/libnvidia-container/gpgkey
    dest: /etc/apt/keyrings/nvidia-container-toolkit.asc
    mode: '0644'
  when: nvidia_container_runtime
  check_mode: no

- name: Add NVIDIA Container Toolkit repository to APT sources
  apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/nvidia-container-toolkit.asc] https://nvidia.github.io/libnvidia-container/stable/deb/amd64 /"
    state: present
  when: nvidia_container_runtime

- name: Update APT cache
  ansible.builtin.apt:
    update_cache: yes
  when: nvidia_container_runtime

- name: Install NVIDIA Container Toolkit
  apt:
    name: nvidia-container-toolkit
    state: present
    update_cache: yes
  when: nvidia_container_runtime

- name: Make sure docker is started and enabled
  service:
    name: docker
    state: started
    enabled: yes

### Install Loki Docker logging driver plugin (router only)
- name: Install Loki Docker logging driver plugin
  community.docker.docker_plugin:
    plugin_name: grafana/loki-docker-driver:2.9.2
    alias: loki
    state: present
  when: not is_satellite
  ignore_errors: yes  # Don't fail if plugin already exists

### Configure docker daemon on host
- name: Docker daemon config file
  ansible.builtin.template:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/daemon.json' }}"
    dest: '/etc/docker/daemon.json'
    owner: root
    group: root
    mode: 0600
  register: docker_conf

- name: Restart Docker to pick up daemon config changes
  ansible.builtin.systemd:
    name: docker
    state: restarted
  when: docker_conf.changed and not ansible_check_mode

#- name: ensure required pip-packages are installed on host
#  pip:
#    name:
#      - docker
#      - PyYAML
#      - docker-compose

### Docker socket proxy TLS certificates
# Generate self-signed CA + server + client certs for mTLS between CI runners
# and lab_nginx (which proxies to docker-socket-proxy). Certs are 10-year validity.
- name: Create docker-proxy-tls cert directory
  ansible.builtin.file:
    path: "{{ docker_persistent_data_path }}/docker-proxy-tls"
    state: directory
    mode: '0755'

- name: Check docker-proxy-tls cert files
  ansible.builtin.stat:
    path: "{{ docker_persistent_data_path }}/docker-proxy-tls/{{ item }}"
  loop:
    - ca.pem
    - cert.pem
    - key.pem
    - server-cert.pem
    - server-key.pem
  register: docker_proxy_tls_certs

- name: Purge docker-proxy-tls directory if any cert is missing or a directory
  ansible.builtin.file:
    path: "{{ docker_persistent_data_path }}/docker-proxy-tls"
    state: absent
  when: docker_proxy_tls_certs.results | selectattr('stat.exists', 'equalto', false) | list | length > 0 or
        docker_proxy_tls_certs.results | selectattr('stat.isdir', 'defined') | selectattr('stat.isdir', 'equalto', true) | list | length > 0

- name: Recreate docker-proxy-tls cert directory after purge
  ansible.builtin.file:
    path: "{{ docker_persistent_data_path }}/docker-proxy-tls"
    state: directory
    mode: '0755'

- name: Generate docker-proxy-tls certificates
  ansible.builtin.script:
    cmd: "{{ lookup('env', 'CI_PROJECT_DIR') }}/docker/docker-socket-proxy-tls/generate-certs.sh {{ docker_persistent_data_path }}/docker-proxy-tls"
  when: docker_proxy_tls_certs.results | selectattr('stat.exists', 'equalto', false) | list | length > 0 or
        docker_proxy_tls_certs.results | selectattr('stat.isdir', 'defined') | selectattr('stat.isdir', 'equalto', true) | list | length > 0
  register: docker_proxy_tls_generated

- name: Log in to GitLab container registry
  docker_login:
    username: "{{ lookup('env', 'CI_REGISTRY_USER') }}"
    password: "{{ lookup('env', 'CI_REGISTRY_PASSWORD') }}"
    registry_url: "https://gitlab-registry.lab.nkontur.com:443"
  when: gitlab_registry_login | default(true)

- name: Template out compose file to ansible state directory on host
  ansible.builtin.template:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/' + item }}"
    dest: "{{ docker_compose_dest_path + '/' + item }}"
    owner: root
    group: root
    mode: '0700'
  no_log: true
  loop: "{{ docker_compose_file_names }}"

# The following three tasks generate nginx configs dynamically on the CI runner.
# They must run even in check mode so validation can properly test config copying.
- name: Create nginx config output subdir if it does not exist
  ansible.builtin.file:
    path: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/nginx/' + inventory_hostname}}"
    state: directory
    mode: '0755'
  delegate_to: localhost
  check_mode: no

- name: Template out compose file to ansible state directory within container
  ansible.builtin.template:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/' + item }}"
    dest: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/nginx/' + inventory_hostname }}"
    owner: root
    group: root
    mode: '0755'
  changed_when: false
  no_log: true
  loop: "{{ docker_compose_file_names }}"
  delegate_to: localhost
  check_mode: no

- name: Execute Python script to generate nginx custom config files
  shell:
    cmd: "/usr/bin/python3 {{ lookup('env', 'CI_PROJECT_DIR') }}/docker/nginx/generate-configs.py --workspace-path {{ lookup('env', 'CI_PROJECT_DIR') }}/docker/nginx --network {{ item.network }} --output-prefix {{ item.network }}_ --output-subdir {{ inventory_hostname }} {{ item.extra_args | default('') }}"
  delegate_to: localhost
  changed_when: false
  check_mode: no
  loop: "{{ nginx_config | default([]) }}"

- name: initialize nginx conf file dicts
  set_fact: 
    docker_config_nginx: []

- name: create nginx conf file dicts
  set_fact:
    docker_config_nginx: "{{ docker_config_nginx + [{'src': 'docker/nginx/nginx.conf',
                        'dest': item.dest + '/conf/nginx.conf',
                        'name': item.name }, 
                         {'src': 'docker/nginx/' + inventory_hostname + '/' + item.network + '_stream.conf',
                        'dest': item.dest + '/conf/conf.d/stream.conf',
                        'name': item.name },
                        {'src': 'docker/nginx/' + inventory_hostname + '/' + item.network +  '_http.conf',
                        'dest': item.dest + '/conf/conf.d/http.conf',
                        'name': item.name },
                        {'src': 'docker/nginx/ssl_config',
                        'dest': item.dest + '/conf/ssl_config',
                        'name': item.name,
                        'owner': 'systemd-resolve',
                        'group': 'systemd-journal',
                        'mode': '0700'  }] }}"
  loop: "{{ nginx_config | default([]) }}"

- name: Create docker conf directories
  ansible.builtin.file:
    path: "{{ item.dest | dirname }}"
    state: directory
  loop: "{{ docker_config + (docker_config_nginx | default([])) }}"

- name: Create docker data directories with specific ownership
  ansible.builtin.file:
    path: "{{ item.path }}"
    state: directory
    owner: "{{ item.owner | default('root') }}"
    group: "{{ item.group | default('root') }}"
    mode: "{{ item.mode | default('0755') }}"
  loop: "{{ docker_data_dirs | default([]) }}"

### Deploy static website files for nkontur.com
- name: Create nkontur.com webroot directory
  ansible.builtin.file:
    path: "{{ docker_persistent_data_path }}/nginx/webroot/nkontur.com"
    state: directory
    mode: '0755'
  when: "'external' in (nginx_config | default([]) | map(attribute='network') | list)"

- name: Synchronize nkontur.com website files
  ansible.posix.synchronize:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') }}/docker/nginx/sites/nkontur.com/"
    dest: "{{ docker_persistent_data_path }}/nginx/webroot/nkontur.com/"
    delete: yes
    recursive: yes
  when: "'external' in (nginx_config | default([]) | map(attribute='network') | list)"

- name: Copy docker configuration files
  ansible.builtin.template:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') }}/{{ item.src }}"
    dest: "{{ item.dest }}"
    owner: "{{ item.owner | default('root') }}"
    group: "{{ item.owner | default('root') }}"
    mode: "{{ item.mode | default('0644') }}"
  register: docker_config_copy
  loop: "{{ docker_config + (docker_config_nginx | default([])) }}"

- name: Rebuild Docker images for changed Dockerfiles
  ansible.builtin.command:
    cmd: "docker compose -f {{ docker_compose_dest_path }}/docker-compose.yml build --no-cache {{ item.item.name }}"
  loop: "{{ docker_config_copy.results | selectattr('item.src', 'search', 'Dockerfile$') | selectattr('changed', 'equalto', true) | list }}"
  loop_control:
    label: "{{ item.item.name }}"
  when: not ansible_check_mode

- name: Create and start Docker services
  community.docker.docker_compose_v2:
    project_name: "{{ docker_compose_project_name | default('docker') }}"
    project_src: "{{ docker_compose_dest_path }}/"
    files: "{{ docker_compose_file_names }}"
    state: present
  when: not ansible_check_mode

- name: Force recreate containers after daemon config change
  community.docker.docker_compose_v2:
    project_name: "{{ docker_compose_project_name | default('docker') }}"
    project_src: "{{ docker_compose_dest_path }}/"
    files: "{{ docker_compose_file_names }}"
    state: present
    recreate: always
  when: docker_conf.changed and not ansible_check_mode

- name: Enable dnsmasq.d config loading for Pi-hole
  ansible.builtin.replace:
    path: "{{ docker_persistent_data_path }}/pihole/conf/pihole.toml"
    regexp: '^\s*etc_dnsmasq_d\s*=\s*false'
    replace: '  etc_dnsmasq_d = true'
  register: pihole_dnsmasq_d
  when: not ansible_check_mode
  ignore_errors: yes

- name: Set Pi-hole listening mode to ALL for cross-VLAN DNS
  ansible.builtin.replace:
    path: "{{ docker_persistent_data_path }}/pihole/conf/pihole.toml"
    regexp: '^\s*listeningMode\s*=\s*"LOCAL"'
    replace: '  listeningMode = "ALL"'
  register: pihole_listening_mode
  when: not ansible_check_mode
  ignore_errors: yes

- name: Restart containers if config change
  ansible.builtin.command:
    cmd: "docker restart {{ item.item.name }}"
  when: item.changed and not ansible_check_mode
  loop: "{{ docker_config_copy.results }}"
  ignore_errors: yes

- name: Restart pihole if pihole.toml was modified
  ansible.builtin.command:
    cmd: "docker restart pihole"
  when: (pihole_dnsmasq_d is changed or pihole_listening_mode is changed) and not ansible_check_mode

- name: Configure Pi-hole local DNS records via pihole-FTL
  ansible.builtin.command:
    cmd: >-
      docker exec pihole pihole-FTL --config dns.hosts
      '{{ pihole_dns_hosts | to_json }}'
  when:
    - pihole_dns_hosts is defined
    - not ansible_check_mode
  changed_when: true

# Deluge cache fix: reduce libtorrent disk cache to prevent excessive RAM usage.
# Default cache_size of 512 pieces causes 28GB+ memory consumption with large torrents.
# Repo-managed core.conf sets cache_size to 128, keeping usage under 2GB.
- name: Check if deluge data directory exists
  ansible.builtin.stat:
    path: "{{ docker_persistent_data_path }}/deluge"
  register: deluge_dir

- name: Deploy Deluge core.conf (managed cache_size)
  ansible.builtin.copy:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/deluge/core.conf' }}"
    dest: "{{ docker_persistent_data_path }}/deluge/core.conf"
    owner: root
    group: root
    mode: '0644'
  register: deluge_config
  when: deluge_dir.stat.exists and not ansible_check_mode

- name: Restart deluge if config was modified
  ansible.builtin.command:
    cmd: "docker restart deluge"
  when: deluge_dir.stat.exists and deluge_config is changed and not ansible_check_mode

### Transcript credential scrubbing cron
# Uses gitleaks (~160 rules) to detect and redact secrets from OpenClaw
# session transcripts. Also purges archived sub-agent transcripts older
# than 7 days. Gitleaks runs natively on the host.
- name: Install gitleaks binary
  ansible.builtin.shell: |
    set -euo pipefail
    GITLEAKS_VERSION="8.30.0"
    DEST="/usr/local/bin/gitleaks"
    if [[ -x "$DEST" ]] && "$DEST" version 2>/dev/null | grep -q "$GITLEAKS_VERSION"; then
      echo "gitleaks ${GITLEAKS_VERSION} already installed"
      exit 0
    fi
    URL="https://github.com/gitleaks/gitleaks/releases/download/v${GITLEAKS_VERSION}/gitleaks_${GITLEAKS_VERSION}_linux_x64.tar.gz"
    TMP=$(mktemp -d)
    curl -fsSL -o "${TMP}/gitleaks.tar.gz" "$URL"
    tar xzf "${TMP}/gitleaks.tar.gz" -C "$TMP" gitleaks
    install -m 0755 "${TMP}/gitleaks" "$DEST"
    rm -rf "$TMP"
  args:
    executable: /bin/bash
  register: gitleaks_install
  changed_when: "'already installed' not in gitleaks_install.stdout"

- name: Create scrub-transcripts config directory
  ansible.builtin.file:
    path: /etc/scrub-transcripts
    state: directory
    owner: root
    group: root
    mode: '0755'

- name: Deploy transcript scrub script
  ansible.builtin.copy:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/scrub-transcripts/scrub-transcripts.sh' }}"
    dest: "/usr/local/bin/scrub-transcripts.sh"
    owner: root
    group: root
    mode: '0755'

- name: Deploy gitleaks config for transcript scrubbing
  ansible.builtin.copy:
    src: "{{ lookup('env', 'CI_PROJECT_DIR') + '/docker/scrub-transcripts/gitleaks-transcripts.toml' }}"
    dest: "/etc/scrub-transcripts/gitleaks-transcripts.toml"
    owner: root
    group: root
    mode: '0644'

- name: Set up transcript scrub cron job (every 10 minutes)
  ansible.builtin.cron:
    name: "Scrub credentials from moltbot transcripts"
    minute: "*/10"
    job: >-
      /usr/local/bin/scrub-transcripts.sh {{ docker_persistent_data_path }}/moltbot/data/agents/main/sessions 2>&1 | logger -t scrub-transcripts

- name: Daily chromium-browser restart (clear tabs and free memory)
  ansible.builtin.cron:
    name: "Restart chromium-browser daily"
    minute: "0"
    hour: "4"
    job: "docker restart chromium-browser 2>&1 | logger -t chromium-restart"
